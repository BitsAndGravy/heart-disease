{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3612a8d",
   "metadata": {},
   "source": [
    "# Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc370d4",
   "metadata": {},
   "source": [
    "## I. Project Tasks\n",
    "\n",
    "### Define your scope\n",
    "My primary goal is to continue using the skills I learned on Codecademy. Specifically, I want to clean/tidy data, look for trends, and create a visualization that tells a story. This is a low-key project; machine learning and data mining algorithms are outside of my scope. After thinking it over, I think I will look for correlations and run statistical tests (i.e. Pearson) in Jupyter, and display the highest correlating variables in Tableau.\n",
    "\n",
    "### Decide on a question or topic\n",
    "I decided to choose a topic related to medicine - heart disease. I dispense all kinds of medications that treat heart conditions on a daily basis.\n",
    "\n",
    "### Find a dataset\n",
    "I went to kaggle and found the dataset \"Heart Disease Dataset\" provided by Mexwell (link here https://www.kaggle.com/datasets/mexwell/heart-disease-dataset).\n",
    "\n",
    "### Define your problem\n",
    "After a brief glance at the dataset and the documentation, I would like to find what makes people with heart disease different from those without heart disease. \n",
    "\n",
    "### Load and check data\n",
    "Documentation is mostly clear (the Units column consists of units and/or ranges and/or descriptions\n",
    ") and I can identify what each variable is measuring, except for the ST segment variables. Specifically, for the 'oldpeak' variable, I do not know what the numbers represents (documentation says the units are 'depression'), and how it relates to the 'ST slope' variable. I was not familiar with the term 'old peak', and decided to familiarize myself with it before getting too far along.\n",
    "\n",
    "I found that the units for _oldpeak_ are likely mm on an EKG. The first hits on Google were unhelpful, and I am making this assumption based on what I read about ST slopes.\n",
    "\n",
    "Image describing ST slopes: https://litfl.com/wp-content/uploads/2018/10/ST-segment-depression-upsloping-downsloping-horizontal.png\n",
    "\n",
    "\n",
    "### Data wrangling and tidying (in progress)\n",
    "Kaggle gave this dataset a score of 10.00 out of 10.00 for usability, but one person on Kaggle commented that about 150 people had a cholesterol level of zero, so I will review the dataset for missing values or other possible errors. \n",
    "\n",
    "### Find the story (to do)\n",
    "What, in one sentence, do you want your audience to take away from your project? You may have to create all of your visualizations, do all of your explorations, and even get feedback before you know what it is. But, take a moment to decide the one thing people should take away from your project and make that the first thing. Make that story the easiest one to find.\n",
    "\n",
    "### Communicate your findings (to do)\n",
    "This could be in the shape of a report, a Tableau Dashboard, a slide deck, etc. The best way to decide is to imagine your audience. Who are they? Where do you envision reaching them? What is the best medium for that?\\\n",
    "Do you want to reach other people interested in your topic? Do you want to persuade someone to care about something? Do you want to focus on business stakeholders? Where might you find each group? Tailor your project to that imagined scenario.\\\n",
    "From there, you can start to create a project to communicate your story with them.\n",
    "\n",
    "### Wrap up (to do)\n",
    "This step might be the most impactful for finding a job. Now that youâ€™ve written your report, created your deck, or built your dashboard, check your work. Go through and proofread. Try to view your project from wherever you decided to host it. Make sure that all of the links work, and ask a friend (or visit the forums) to find someone to go through it and tell you if there are any inconsistencies, jumps of logic, or confusing parts. This final round of checks is essential for creating a polished project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04563723",
   "metadata": {},
   "source": [
    "## II. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2591e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import numpy as np\n",
    "heart_df = pd.read_csv(r'C:\\Users\\jsbit\\OneDrive\\Documents\\Coding 2023\\Git\\heart-disease\\heart_statlog_cleveland_hungary_final.csv', encoding_errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177fbff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1190 participants in this dataset.\n"
     ]
    }
   ],
   "source": [
    "print('There were', str(len(heart_df)), 'participants in this dataset.')\n",
    "# Although 1,190 participants is a lot, 'heart disease' is a large umbrella term and can affect almost anyone.\n",
    "# Therefore, I estimate that this dataset not meet power and we can't extrapolate findings to the general public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41afdd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names are:\n",
      " Index(['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol',\n",
      "       'fasting blood sugar', 'resting ecg', 'max heart rate',\n",
      "       'exercise angina', 'oldpeak', 'ST slope', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"The column names are:\\n\", heart_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ec3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation of changes to variable names:\n",
    "    # Because of my German heritage, I prefer EKG instead of ECG.\n",
    "    # I see an inconsistenct in abbreviating 'bp', but spelling out 'blood sugar', so I will abbreviate them all.\n",
    "        # For clarification I added 'systolic' before 'bp'\n",
    "    # I think 'ST depression' is a better variable name than 'oldpeak'. \n",
    "        # I can't find much information on why it is called old peak\n",
    "        # It's a measure of the ST depression in mm on an EKG\n",
    "        # If it's a measure of depression, why is it called peak?\n",
    "    # I decided I prefer the variable name 'stress_test' over 'exercise_angina', \n",
    "        # especially since I will be converting values to 'angina' or 'no angina'\n",
    "    # I prefer 'heart disease category' to 'target', it feels more descriptive\n",
    "\n",
    "heart_df = heart_df.rename(columns={'resting ecg': 'ekg', \n",
    "                                    'chest pain type': 'pain type', \n",
    "                                    'fasting blood sugar': 'fbs', \n",
    "                                    'max heart rate': 'max hr', \n",
    "                                    'resting bp s': 'systolic bp',\n",
    "                                    'oldpeak': 'ST depression',\n",
    "                                    'exercise angina': 'stress test',\n",
    "                                    'target': 'heart disease category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f241f7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new column names are:\n",
      " Index(['age', 'sex', 'pain_type', 'systolic_bp', 'cholesterol', 'fbs', 'ekg',\n",
      "       'max_hr', 'stress_test', 'ST_depression', 'ST_slope',\n",
      "       'heart_disease_category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# While I'm at it, might as well replace spaces with underscores.\n",
    "heart_df.columns = [variable.replace(' ', '_') for variable in heart_df]\n",
    "\n",
    "print(\"The new column names are:\\n\", heart_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2976e041",
   "metadata": {},
   "source": [
    "## III. Initial Exploratory Data Analysis\n",
    "### Dataset overview and descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c431213c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age          sex    pain_type  systolic_bp  cholesterol  \\\n",
      "count  1190.000000  1190.000000  1190.000000  1190.000000  1190.000000   \n",
      "mean     53.720168     0.763866     3.232773   132.153782   210.363866   \n",
      "std       9.358203     0.424884     0.935480    18.368823   101.420489   \n",
      "min      28.000000     0.000000     1.000000     0.000000     0.000000   \n",
      "25%      47.000000     1.000000     3.000000   120.000000   188.000000   \n",
      "50%      54.000000     1.000000     4.000000   130.000000   229.000000   \n",
      "75%      60.000000     1.000000     4.000000   140.000000   269.750000   \n",
      "max      77.000000     1.000000     4.000000   200.000000   603.000000   \n",
      "\n",
      "               fbs          ekg       max_hr  stress_test  ST_depression  \\\n",
      "count  1190.000000  1190.000000  1190.000000  1190.000000    1190.000000   \n",
      "mean      0.213445     0.698319   139.732773     0.387395       0.922773   \n",
      "std       0.409912     0.870359    25.517636     0.487360       1.086337   \n",
      "min       0.000000     0.000000    60.000000     0.000000      -2.600000   \n",
      "25%       0.000000     0.000000   121.000000     0.000000       0.000000   \n",
      "50%       0.000000     0.000000   140.500000     0.000000       0.600000   \n",
      "75%       0.000000     2.000000   160.000000     1.000000       1.600000   \n",
      "max       1.000000     2.000000   202.000000     1.000000       6.200000   \n",
      "\n",
      "          ST_slope  heart_disease_category  \n",
      "count  1190.000000             1190.000000  \n",
      "mean      1.624370                0.528571  \n",
      "std       0.610459                0.499393  \n",
      "min       0.000000                0.000000  \n",
      "25%       1.000000                0.000000  \n",
      "50%       2.000000                1.000000  \n",
      "75%       2.000000                1.000000  \n",
      "max       3.000000                1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(heart_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6136052",
   "metadata": {},
   "source": [
    "* Each variable has a count of 1,190, so it's free of NAN.\n",
    "* I know that some values are zero; this is just initial exploration and I will review these numbers again later.\n",
    "* Age:\n",
    "    * I am somewhat surprised that the max age was only 77; it would be nice to know the inclusion criteria for these studies (i.e. if there was a max age for some but not others).\n",
    "    * It looks like this will have a normal distribution; the distance of the 25th and 75th percentile from the median and the distance of the min and max from the median are similar.\n",
    "* Sex: The mean and median indicate that most participants were male.\n",
    "* Resting blood pressure (systolic):\n",
    "    * Minimum was zero; not a realistic number.\n",
    "    * The average seems lower than I might have guessed. I am assuming that lots of people have high blood pressure (i.e. systolic over 130 mmHg), hopefully it isn't skewed a lot by missing/zero values.\n",
    "* Cholesterol:\n",
    "    * Minimum was zero; not a realistic number.\n",
    "    * It seems like most people had an elevated cholesterol (over 200 mg/dL)\n",
    "* Fasting blood sugar over 120 mg/dL: Looks like most people were normal (value of zero).\n",
    "* Max heart rate (during stress test and in beats per minute, I assume):\n",
    "    * I don't normally see stress test results, so this is interesting data to me.\n",
    "    * A min of 60 bpm - someone must be on some strong beta blockers or experienced angina rather quickly.\n",
    "* Exercise-induced angina: Looks like most people did not experience angina.\n",
    "* Oldpeak: This could get trippy - a negative ST depression is ST elevation (min of -2.6 mm)\n",
    "* Target: A slight majority were classified as having heart disease.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d483969",
   "metadata": {},
   "source": [
    "## IV. Data wrangling and tidying\n",
    "\n",
    "### Data types and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31bde4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190 entries, 0 to 1189\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   age                     1190 non-null   int64  \n",
      " 1   sex                     1190 non-null   int64  \n",
      " 2   pain_type               1190 non-null   int64  \n",
      " 3   systolic_bp             1190 non-null   int64  \n",
      " 4   cholesterol             1190 non-null   int64  \n",
      " 5   fbs                     1190 non-null   int64  \n",
      " 6   ekg                     1190 non-null   int64  \n",
      " 7   max_hr                  1190 non-null   int64  \n",
      " 8   stress_test             1190 non-null   int64  \n",
      " 9   ST_depression           1190 non-null   float64\n",
      " 10  ST_slope                1190 non-null   int64  \n",
      " 11  heart_disease_category  1190 non-null   int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 111.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(heart_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64c16e",
   "metadata": {},
   "source": [
    "#### Data values\n",
    "* Leave as numbers:\n",
    "    * age\n",
    "    * systolic_bp \n",
    "    * cholesterol\n",
    "    * max_hr\n",
    "    * ST_depression\n",
    "    \n",
    "* Change from numbers to description (using description found in documentation unless otherwise noted):\n",
    "    * sex: 0: female, 1: male\n",
    "    * pain_type: 1: typical, 2: atypical, 3: non-anginal, 4: asymptomatic\n",
    "    * fbs (using my own words): 0: normal, 1: elevated\n",
    "    * ekg (using my own words): 0: normal, 1: ST abnormality, 2: LVH (abbreviated from left ventricular hypertrophy)\n",
    "    * stress_test: 0: no angina, 1: angina\n",
    "    * ST_slope: 0 (my own words - not found in documentation): not evaluated, 1: upsloping, 2: flat, 3: downsloping\n",
    "    * heart_disease_category: 0: normal, 1: heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b72767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for the sex variable: ['male' 'female']\n",
      "Values for pain type: ['atypical' 'non-anginal' 'asymptomatic' 'typical']\n",
      "Values for fasting blood sugar: ['normal' 'elevated']\n",
      "Values for EKG: ['normal' 'ST abnormality' 'LVH']\n",
      "Values for stress test: ['no angina' 'angina']\n",
      "Values for ST slope: ['upsloping' 'flat' 'downsloping' 'not evaluated']\n",
      "Values for heart disease category: ['normal' 'heart disease']\n"
     ]
    }
   ],
   "source": [
    "heart_df['sex'] = heart_df.sex.replace(\n",
    "    0, 'female').replace(\n",
    "    1, 'male')\n",
    "\n",
    "heart_df['pain_type'] = heart_df.pain_type.replace(\n",
    "    1, 'typical').replace(\n",
    "    2, 'atypical').replace(\n",
    "    3, 'non-anginal').replace(\n",
    "    4, 'asymptomatic')\n",
    "\n",
    "heart_df['fbs'] = heart_df.fbs.replace(\n",
    "    0, 'normal').replace(\n",
    "    1, 'elevated')\n",
    "\n",
    "heart_df['ekg'] = heart_df.ekg.replace(\n",
    "    0, 'normal').replace(\n",
    "    1, 'ST abnormality').replace(\n",
    "    2, 'LVH')\n",
    "\n",
    "heart_df['stress_test'] = heart_df.stress_test.replace(\n",
    "    0, 'no angina').replace(\n",
    "    1, 'angina')\n",
    "\n",
    "heart_df['ST_slope'] = heart_df.ST_slope.replace(\n",
    "    0, 'not evaluated').replace(\n",
    "    1, 'upsloping').replace(\n",
    "    2, 'flat').replace(\n",
    "    3, 'downsloping')\n",
    "\n",
    "heart_df['heart_disease_category'] = heart_df.heart_disease_category.replace(\n",
    "    0, 'normal').replace(\n",
    "    1, 'heart disease')\n",
    "\n",
    "print('Values for the sex variable:', str(heart_df.sex.unique()))\n",
    "print('Values for pain type:', str(heart_df.pain_type.unique()))\n",
    "print('Values for fasting blood sugar:', str(heart_df.fbs.unique()))\n",
    "print('Values for EKG:', str(heart_df.ekg.unique()))\n",
    "print('Values for stress test:', str(heart_df.stress_test.unique()))\n",
    "print('Values for ST slope:', str(heart_df.ST_slope.unique()))\n",
    "print('Values for heart disease category:', str(heart_df.heart_disease_category.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d9a4d",
   "metadata": {},
   "source": [
    "#### Data types\n",
    "* Appropriate data type:\n",
    "    * Age\n",
    "    * Blood pressure, systolic (systolic_bp)\n",
    "    * Cholesterol\n",
    "    * Max heart rate\n",
    "    * ST depression\n",
    "    \n",
    "* Needs changed:\n",
    "    * Sex: Binary nominal categotical\n",
    "    * Pain type: Nominal categorical\n",
    "    * EKG: Nominal categorical\n",
    "    * Fasting blood sugar (fbs)\n",
    "    * Exercise-induced angina: Binary nominal categorical\n",
    "    * ST slope: Ordinal categorical\n",
    "    * Heart disease category: Nominal categorical  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "088841aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types for all variables:\n",
      " age                          int64\n",
      "sex                       category\n",
      "pain_type                 category\n",
      "systolic_bp                  int64\n",
      "cholesterol                  int64\n",
      "fbs                       category\n",
      "ekg                       category\n",
      "max_hr                       int64\n",
      "stress_test               category\n",
      "ST_depression              float64\n",
      "ST_slope                  category\n",
      "heart_disease_category    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "heart_df = heart_df.astype({\n",
    "    'sex': 'category',\n",
    "    'pain_type': 'category',\n",
    "    'ekg': 'category',\n",
    "    'fbs': 'category', \n",
    "    'stress_test': 'category',\n",
    "    'ST_slope': 'category',\n",
    "    'heart_disease_category': 'category'})\n",
    "\n",
    "print('Data types for all variables:\\n', heart_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046cba04",
   "metadata": {},
   "source": [
    "### Checking for and handling duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ddf1fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  age     sex     pain_type  systolic_bp  cholesterol       fbs  \\\n",
      "0      163   49  female      atypical          110          208    normal   \n",
      "1      604   58    male   non-anginal          150          219    normal   \n",
      "2      887   63    male       typical          145          233  elevated   \n",
      "3      888   67    male  asymptomatic          160          286    normal   \n",
      "4      889   67    male  asymptomatic          120          229    normal   \n",
      "..     ...  ...     ...           ...          ...          ...       ...   \n",
      "267   1156   42    male   non-anginal          130          180    normal   \n",
      "268   1157   61    male  asymptomatic          140          207    normal   \n",
      "269   1158   66    male  asymptomatic          160          228    normal   \n",
      "270   1159   46    male  asymptomatic          140          311    normal   \n",
      "271   1160   71  female  asymptomatic          112          149    normal   \n",
      "\n",
      "                ekg  max_hr stress_test  ST_depression     ST_slope  \\\n",
      "0            normal     160   no angina            0.0    upsloping   \n",
      "1    ST abnormality     118      angina            0.0         flat   \n",
      "2               LVH     150   no angina            2.3  downsloping   \n",
      "3               LVH     108      angina            1.5         flat   \n",
      "4               LVH     129      angina            2.6         flat   \n",
      "..              ...     ...         ...            ...          ...   \n",
      "267          normal     150   no angina            0.0    upsloping   \n",
      "268             LVH     138      angina            1.9    upsloping   \n",
      "269             LVH     138   no angina            2.3    upsloping   \n",
      "270          normal     120      angina            1.8         flat   \n",
      "271          normal     125   no angina            1.6         flat   \n",
      "\n",
      "    heart_disease_category  \n",
      "0                   normal  \n",
      "1            heart disease  \n",
      "2                   normal  \n",
      "3            heart disease  \n",
      "4            heart disease  \n",
      "..                     ...  \n",
      "267                 normal  \n",
      "268          heart disease  \n",
      "269                 normal  \n",
      "270          heart disease  \n",
      "271                 normal  \n",
      "\n",
      "[272 rows x 13 columns]\n",
      "0       163\n",
      "1       604\n",
      "2       887\n",
      "3       888\n",
      "4       889\n",
      "5       890\n",
      "6       891\n",
      "7       892\n",
      "8       893\n",
      "9       894\n",
      "10      895\n",
      "11      896\n",
      "12      897\n",
      "13      898\n",
      "14      899\n",
      "15      900\n",
      "16      901\n",
      "17      902\n",
      "18      903\n",
      "19      904\n",
      "20      905\n",
      "21      906\n",
      "22      907\n",
      "23      908\n",
      "24      909\n",
      "25      910\n",
      "26      911\n",
      "27      912\n",
      "28      913\n",
      "29      914\n",
      "30      915\n",
      "31      916\n",
      "32      917\n",
      "33      918\n",
      "34      919\n",
      "35      920\n",
      "36      921\n",
      "37      922\n",
      "38      923\n",
      "39      924\n",
      "40      925\n",
      "41      926\n",
      "42      927\n",
      "43      928\n",
      "44      929\n",
      "45      930\n",
      "46      931\n",
      "47      932\n",
      "48      933\n",
      "49      934\n",
      "50      935\n",
      "51      936\n",
      "52      937\n",
      "53      938\n",
      "54      939\n",
      "55      940\n",
      "56      941\n",
      "57      942\n",
      "58      943\n",
      "59      944\n",
      "60      945\n",
      "61      946\n",
      "62      947\n",
      "63      948\n",
      "64      949\n",
      "65      950\n",
      "66      951\n",
      "67      952\n",
      "68      953\n",
      "69      954\n",
      "70      955\n",
      "71      956\n",
      "72      957\n",
      "73      958\n",
      "74      959\n",
      "75      960\n",
      "76      961\n",
      "77      962\n",
      "78      963\n",
      "79      964\n",
      "80      965\n",
      "81      966\n",
      "82      967\n",
      "83      968\n",
      "84      969\n",
      "85      970\n",
      "86      971\n",
      "87      972\n",
      "88      973\n",
      "89      975\n",
      "90      976\n",
      "91      977\n",
      "92      978\n",
      "93      979\n",
      "94      980\n",
      "95      981\n",
      "96      982\n",
      "97      983\n",
      "98      984\n",
      "99      985\n",
      "100     986\n",
      "101     987\n",
      "102     988\n",
      "103     989\n",
      "104     990\n",
      "105     991\n",
      "106     992\n",
      "107     993\n",
      "108     994\n",
      "109     995\n",
      "110     996\n",
      "111     997\n",
      "112     998\n",
      "113     999\n",
      "114    1000\n",
      "115    1001\n",
      "116    1002\n",
      "117    1003\n",
      "118    1004\n",
      "119    1005\n",
      "120    1006\n",
      "121    1007\n",
      "122    1008\n",
      "123    1009\n",
      "124    1010\n",
      "125    1011\n",
      "126    1012\n",
      "127    1013\n",
      "128    1014\n",
      "129    1015\n",
      "130    1016\n",
      "131    1017\n",
      "132    1018\n",
      "133    1019\n",
      "134    1020\n",
      "135    1021\n",
      "136    1022\n",
      "137    1023\n",
      "138    1024\n",
      "139    1025\n",
      "140    1026\n",
      "141    1027\n",
      "142    1028\n",
      "143    1029\n",
      "144    1030\n",
      "145    1031\n",
      "146    1032\n",
      "147    1033\n",
      "148    1034\n",
      "149    1035\n",
      "150    1036\n",
      "151    1037\n",
      "152    1038\n",
      "153    1039\n",
      "154    1040\n",
      "155    1041\n",
      "156    1042\n",
      "157    1043\n",
      "158    1044\n",
      "159    1045\n",
      "160    1046\n",
      "161    1047\n",
      "162    1048\n",
      "163    1049\n",
      "164    1050\n",
      "165    1051\n",
      "166    1052\n",
      "167    1054\n",
      "168    1055\n",
      "169    1056\n",
      "170    1057\n",
      "171    1058\n",
      "172    1059\n",
      "173    1060\n",
      "174    1061\n",
      "175    1062\n",
      "176    1063\n",
      "177    1064\n",
      "178    1065\n",
      "179    1066\n",
      "180    1067\n",
      "181    1068\n",
      "182    1069\n",
      "183    1070\n",
      "184    1071\n",
      "185    1072\n",
      "186    1073\n",
      "187    1074\n",
      "188    1075\n",
      "189    1076\n",
      "190    1077\n",
      "191    1078\n",
      "192    1080\n",
      "193    1081\n",
      "194    1082\n",
      "195    1083\n",
      "196    1084\n",
      "197    1085\n",
      "198    1086\n",
      "199    1087\n",
      "200    1088\n",
      "201    1089\n",
      "202    1090\n",
      "203    1091\n",
      "204    1092\n",
      "205    1093\n",
      "206    1094\n",
      "207    1095\n",
      "208    1096\n",
      "209    1097\n",
      "210    1098\n",
      "211    1099\n",
      "212    1100\n",
      "213    1101\n",
      "214    1102\n",
      "215    1103\n",
      "216    1104\n",
      "217    1105\n",
      "218    1106\n",
      "219    1107\n",
      "220    1108\n",
      "221    1109\n",
      "222    1110\n",
      "223    1111\n",
      "224    1112\n",
      "225    1113\n",
      "226    1114\n",
      "227    1115\n",
      "228    1116\n",
      "229    1117\n",
      "230    1118\n",
      "231    1119\n",
      "232    1120\n",
      "233    1121\n",
      "234    1122\n",
      "235    1123\n",
      "236    1124\n",
      "237    1125\n",
      "238    1126\n",
      "239    1127\n",
      "240    1128\n",
      "241    1129\n",
      "242    1130\n",
      "243    1131\n",
      "244    1132\n",
      "245    1133\n",
      "246    1134\n",
      "247    1135\n",
      "248    1136\n",
      "249    1137\n",
      "250    1138\n",
      "251    1139\n",
      "252    1140\n",
      "253    1141\n",
      "254    1142\n",
      "255    1143\n",
      "256    1144\n",
      "257    1145\n",
      "258    1146\n",
      "259    1147\n",
      "260    1148\n",
      "261    1149\n",
      "262    1150\n",
      "263    1151\n",
      "264    1152\n",
      "265    1154\n",
      "266    1155\n",
      "267    1156\n",
      "268    1157\n",
      "269    1158\n",
      "270    1159\n",
      "271    1160\n"
     ]
    }
   ],
   "source": [
    "duplicated_hearts = heart_df[heart_df.duplicated()].reset_index()\n",
    "print(duplicated_hearts)\n",
    "# The index numbers seem interesting in how they are consecutive - are they all that way?\n",
    "print(duplicated_hearts['index'].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7b66379",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       163\n",
      "1       604\n",
      "2       887\n",
      "3       888\n",
      "4       889\n",
      "       ... \n",
      "267    1156\n",
      "268    1157\n",
      "269    1158\n",
      "270    1159\n",
      "271    1160\n",
      "Name: index, Length: 272, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(duplicated_hearts['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94939d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    }
   ],
   "source": [
    "# Yes, it looks like each row after row 887 in heart_df is a duplicate. Calculating if visual analysis was accurate:\n",
    "dup_range = 1160-887 + 1\n",
    "other_dups = 2\n",
    "dup_count_check = dup_range + other_dups\n",
    "print(dup_count_check)\n",
    "# Since my calculated guess of 276 is higher than 272, it looks like not all rows in the range 887-1161 are duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994a4f2",
   "metadata": {},
   "source": [
    "##### What percent of the data are duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77bff17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 22.86 % of the data is duplicated.\n"
     ]
    }
   ],
   "source": [
    "perc_dup = round(len(duplicated_hearts) / len(heart_df) * 100, 2)\n",
    "print('About', str(perc_dup), '% of the data is duplicated.')\n",
    "# Almost a quarter of the data is duplicated - that is a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20cb449",
   "metadata": {},
   "source": [
    "##### How many rows would be left after dropping duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dab4b4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There will be 918 rows remaining after dropping duplicates.\n"
     ]
    }
   ],
   "source": [
    "remainder = len(heart_df) - len(duplicated_hearts)\n",
    "print('There will be', str(remainder), 'rows remaining after dropping duplicates.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb54cd",
   "metadata": {},
   "source": [
    "##### Discussion on handling duplicates: \n",
    "The likelihood of having so many duplicates, and the fact that they are basically all grouped together, I think it is safe to drop the duplicates.\\\n",
    "It would have been nice to have a 'trial ID' or 'participant ID' variable, since this dataset is a conglomeration of multiple datasets. I think this would help pinpoint why there are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a81f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918\n"
     ]
    }
   ],
   "source": [
    "heart = heart_df.drop_duplicates()\n",
    "print(len(heart))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ffe4f",
   "metadata": {},
   "source": [
    "### Handling missing data\n",
    "\n",
    "I noticed two lab values with a min of zero, which indicates that the participant was dead. These lab values are:\n",
    "* systolic_bp: Resting blood pressure (systolic)\n",
    "* cholesterol\n",
    "\n",
    "First, I will see how many rows have a zero in these three columns.\n",
    "\n",
    "#### How many values are missing from the bp and cholesterol variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8f5ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 172 rows with a zero.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero_heart = heart[(heart['systolic_bp'] == 0) | (heart['cholesterol'] == 0)]\n",
    "print('There are', str(len(zero_heart)), 'rows with a zero.\\n')\n",
    "# 172 rows is unmanageable for me to look at. I will separate these zeros into their own dataframes and take a closer look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae431fca",
   "metadata": {},
   "source": [
    "#### Identify zeros in resting blood pressure (systolic)\n",
    "\n",
    "I am curious what other numbers might be out there, so I will include rows with bp from zero to 100. 'Normal' values can go down to 90, below which is considered low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0416bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 rows that recorded a resting systolic blood pressure less than 100:\n",
      "\n",
      "     age     sex     pain_type  systolic_bp  cholesterol       fbs  \\\n",
      "228   38    male  asymptomatic           92          117    normal   \n",
      "268   34    male      atypical           98          220    normal   \n",
      "295   32    male       typical           95            0  elevated   \n",
      "305   51    male  asymptomatic           95            0  elevated   \n",
      "310   57    male  asymptomatic           95            0  elevated   \n",
      "315   53    male  asymptomatic           80            0    normal   \n",
      "329   52    male  asymptomatic           95            0  elevated   \n",
      "334   40    male  asymptomatic           95            0  elevated   \n",
      "340   64  female  asymptomatic           95            0  elevated   \n",
      "450   55    male   non-anginal            0            0    normal   \n",
      "520   63    male  asymptomatic           96          305    normal   \n",
      "694   39  female   non-anginal           94          199    normal   \n",
      "834   51    male   non-anginal           94          227    normal   \n",
      "\n",
      "                ekg  max_hr stress_test  ST_depression     ST_slope  \\\n",
      "228          normal     134      angina            2.5         flat   \n",
      "268          normal     150   no angina            0.0    upsloping   \n",
      "295          normal     127   no angina            0.7    upsloping   \n",
      "305          normal     126   no angina            2.2         flat   \n",
      "310          normal     182   no angina            0.7  downsloping   \n",
      "315          normal     141      angina            2.0  downsloping   \n",
      "329          normal      82      angina            0.8         flat   \n",
      "334  ST abnormality     144   no angina            0.0    upsloping   \n",
      "340          normal     145   no angina            1.1  downsloping   \n",
      "450          normal     155   no angina            1.5         flat   \n",
      "520  ST abnormality     121      angina            1.0    upsloping   \n",
      "694          normal     179   no angina            0.0    upsloping   \n",
      "834          normal     154      angina            0.0    upsloping   \n",
      "\n",
      "    heart_disease_category  \n",
      "228          heart disease  \n",
      "268                 normal  \n",
      "295          heart disease  \n",
      "305          heart disease  \n",
      "310          heart disease  \n",
      "315                 normal  \n",
      "329          heart disease  \n",
      "334          heart disease  \n",
      "340          heart disease  \n",
      "450          heart disease  \n",
      "520          heart disease  \n",
      "694                 normal  \n",
      "834                 normal  \n"
     ]
    }
   ],
   "source": [
    "zero_range_bp = heart[heart['systolic_bp'] < 100]\n",
    "\n",
    "print('There are', str(len(zero_range_bp)), 'rows that recorded a resting systolic blood pressure less than 100:\\n')\n",
    "# Thirteen rows is manageable for me to look at.\n",
    "print(zero_range_bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2839a",
   "metadata": {},
   "source": [
    "#### Review of zeros in zero_range_bp\n",
    "* There was one row with a bp of zero. \n",
    "    * This row also had a zero for cholesterol.\n",
    "* There were 12 other rows with a bp less than 100.\n",
    "    * The lowest value was 80, the rest were over 90.\n",
    "    * Eight of these had a cholesterol of zero.\n",
    "\n",
    "#### Handling missing values\n",
    "* The only variables I could realistically check for were bp and cholesterol.\n",
    "* There was only one row with a missing bp and cholesterol.\n",
    "* There were 171 other rows with a missing cholesterol value.\n",
    "* All other variables had complete information, as far as I could tell.\n",
    "* I will replace zero with NAN for the bp and cholesterol columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad6dd414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                         0\n",
      "sex                         0\n",
      "pain_type                   0\n",
      "systolic_bp                 1\n",
      "cholesterol               172\n",
      "fbs                         0\n",
      "ekg                         0\n",
      "max_hr                      0\n",
      "stress_test                 0\n",
      "ST_depression               0\n",
      "ST_slope                    0\n",
      "heart_disease_category      0\n",
      "dtype: int64\n",
      "About 19% of data from the cholesterol column is missing.\n"
     ]
    }
   ],
   "source": [
    "# Replace zero with NAN in the bp and cholesterol columns:\n",
    "heart['systolic_bp'] = heart['systolic_bp'].replace( 0, np.nan)\n",
    "heart['cholesterol'] = heart['cholesterol'].replace( 0, np.nan)\n",
    "\n",
    "# Checking that zeros were replaced:\n",
    "print(heart.isna().sum())\n",
    "\n",
    "# Percent missing values:\n",
    "print('About {}% of data from the cholesterol column is missing.'.format(round(\n",
    "    100*heart['cholesterol'].isna().sum()/len(heart))))\n",
    "# If 1/5 of the data is missing, then the average cholesterol value will go up compared \n",
    "    # to my initial calculations... it was already high at 210"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487151ec",
   "metadata": {},
   "source": [
    "### Tidying the data\n",
    "* All variables appropriately named\n",
    "* All columns are variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78199217",
   "metadata": {},
   "source": [
    "## V. Statistical analyses\n",
    "\n",
    "Current plan: Use correlational statistics to identify variables that have a high correlation with having heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "next things to do: identify how to compare variables - chi square, crosstabs, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
